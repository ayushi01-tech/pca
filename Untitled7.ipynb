{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushi01-tech/pca/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from google.colab import files\n",
        "# Apply PCA to the data to reduce dimensionality\n",
        "pca = PCA(n_components=2)  # Assuming we want the top 2 components\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(f'Explained variance by PC1 and PC2: {explained_variance}')\n",
        "\n",
        "# Visualizing the PCA loadings\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='coolwarm')\n",
        "plt.title('PCA Visualization')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar(label='Microplastic Type')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# Assuming the labels are the last column in the dataset\n",
        "X = data.iloc[:, :-1]  # Features\n",
        "y = data.iloc[:, -1]   # Labels (PS and PE)\n",
        "\n",
        "# Split the data into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f'Training data shape: {X_train.shape}')\n",
        "print(f'Testing data shape: {X_test.shape}')\n",
        "# Apply PCA to the data to reduce dimensionality\n",
        "pca = PCA(n_components=2)  # Assuming we want the top 2 components\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(f'Explained variance by PC1 and PC2: {explained_variance}')\n",
        "\n",
        "# Visualizing the PCA loadings\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='coolwarm')\n",
        "plt.title('PCA Visualization')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar(label='Microplastic Type')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# Initialize and train the SVM model\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Confusion Matrix for SVM\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(cm_svm)\n",
        "\n",
        "# Visualizing the Confusion Matrix\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "plt.imshow(cm_svm, cmap=\"viridis\")\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "# Initialize and train the LDA model\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "lda_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_lda = lda_model.predict(X_test)\n",
        "\n",
        "# Evaluate the LDA model\n",
        "print(\"LDA Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lda))\n",
        "\n",
        "# Confusion Matrix for LDA\n",
        "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
        "print(\"LDA Confusion Matrix:\")\n",
        "print(cm_lda)\n",
        "\n",
        "# Visualizing the Confusion Matrix\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Confusion Matrix - LDA\")\n",
        "plt.imshow(cm_lda, cmap=\"plasma\")\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hI49a1S7h-gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the LDA model\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "lda_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_lda = lda_model.predict(X_test)\n",
        "\n",
        "# Evaluate the LDA model\n",
        "print(\"LDA Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lda))\n",
        "\n",
        "# Confusion Matrix for LDA\n",
        "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
        "print(\"LDA Confusion Matrix:\")\n",
        "print(cm_lda)\n",
        "\n",
        "# Visualizing the Confusion Matrix\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Confusion Matrix - LDA\")\n",
        "plt.imshow(cm_lda, cmap=\"plasma\")\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "# Initialize and train the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Confusion Matrix for Random Forest\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(cm_rf)\n",
        "\n",
        "# Visualizing the Confusion Matrix\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.imshow(cm_rf, cmap=\"cividis\")\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "# Cross-validation for SVM\n",
        "cv_scores_svm = cross_val_score(svm_model, X, y, cv=5)\n",
        "print(f'SVM Cross-Validation Scores: {cv_scores_svm}')\n",
        "print(f'SVM Mean Cross-Validation Score: {cv_scores_svm.mean()*100:.2f}%')\n",
        "\n",
        "# Cross-validation for LDA\n",
        "cv_scores_lda = cross_val_score(lda_model, X, y, cv=5)\n",
        "print(f'LDA Cross-Validation Scores: {cv_scores_lda}')\n",
        "print(f'LDA Mean Cross-Validation Score: {cv_scores_lda.mean()*100:.2f}%')\n",
        "\n",
        "# Cross-validation for Random Forest\n",
        "cv_scores_rf = cross_val_score(rf_model, X, y, cv=5)\n",
        "print(f'Random Forest Cross-Validation Scores: {cv_scores_rf}')\n",
        "print(f'Random Forest Mean Cross-Validation Score: {cv_scores_rf.mean()*100:.2f}%')\n",
        "import joblib\n",
        "\n",
        "# Save the best model (SVM in this case)\n",
        "joblib.dump(svm_model, 'svm_microplastics_model.pkl')\n",
        "\n",
        "# Load the model later (if needed)\n",
        "# loaded_model = joblib.load('svm_microplastics_model.pkl')\n"
      ],
      "metadata": {
        "id": "YuGgWfT7ihUq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtzQbcvgYf66F4USxboFXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}